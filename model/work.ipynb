{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: If using non-distributed training, comment out this entire notebook\n",
    "# cell. This only related to distributed training.\n",
    "\n",
    "# ATTENTION: Beaker engineers have suggested they will expose the hostnames of\n",
    "# all nodes in a future update, so this service discovery will no longer be\n",
    "# needed. When they add this we will remove the service discovery referenced in\n",
    "# the sample notebook. Removing this is ideal as we hardcode ports which may\n",
    "# cause port synchronization issues with many running experiments. Until they\n",
    "# add this, you will need to replicate the service discovery method implemented\n",
    "# in this cell, but only if your distributed training\n",
    "# jobs require explicit hostnames for all nodes. This reference service\n",
    "# discovery implementation is setup for tensorflow, but if using something else\n",
    "# you would just need to prepare the environment variable differently.\n",
    "\n",
    "# ATTENTION: Change the below to your information.\n",
    "BEAKER_WORKSPACE = \"\"\n",
    "BEAKER_USERNAME = \"\"\n",
    "\n",
    "from beaker import Beaker\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "print(\"Sleeping for 60 seconds to allow Beaker to start up\")\n",
    "time.sleep(60)\n",
    "\n",
    "beaker = Beaker.from_env(default_workspace=BEAKER_WORKSPACE)\n",
    "experiments = beaker.experiment.list(author=BEAKER_USERNAME)\n",
    "experiment = experiments[0]\n",
    "\n",
    "node_hostnames = []\n",
    "for job in experiment.jobs:\n",
    "    node = job.node\n",
    "    print(\"job node: \", node)\n",
    "    node = beaker.node.get(node)\n",
    "    node_hostnames.append(node.hostname)\n",
    "\n",
    "ports = [32916, 43727, 49122, 19253, 60973, 15021, 47468, 23282, 63942, 54812]\n",
    "\n",
    "worker_addresses = [f\"{host}:{port}\" for host, port in zip(node_hostnames, ports)]\n",
    "\n",
    "# Read BEAKER_REPLICA_RANK from environment variable, default to 0 if not set\n",
    "replica_rank = int(os.getenv(\"BEAKER_REPLICA_RANK\", 0))\n",
    "\n",
    "# ATTENTION: This is tensorflow specific. Change if using something different.\n",
    "tf_config = {\n",
    "    \"cluster\": {\n",
    "        \"worker\": worker_addresses\n",
    "    },\n",
    "    \"task\": {\n",
    "        \"type\": \"worker\",\n",
    "        \"index\": replica_rank\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to JSON string with pretty formatting\n",
    "tf_config_json = json.dumps(tf_config)\n",
    "\n",
    "# Print the export command to set the environment variable\n",
    "print(f\"export TF_CONFIG='{tf_config_json}'\")\n",
    "os.environ[\"TF_CONFIG\"] = tf_config_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated work\n",
    "for i in range(10):\n",
    "    print(f\"Worker {replica_rank} is running iteration {i}\")\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
